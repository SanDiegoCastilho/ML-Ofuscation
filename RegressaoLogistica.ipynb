{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulação de dados\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Métricas de classificação\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "#Ignorar Erros\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Regressão\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Split de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Seleção de feature\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(y_test, pred_test):\n",
    "    \"\"\"\n",
    "    Mostra a matriz de confusão.\n",
    "    \"\"\"\n",
    "    #plt.figure()\n",
    "    classes = ['Normal', 'Obfuscated']\n",
    "    cm = confusion_matrix(y_test, pred_test)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x=j, y=i, s=cm[i, j], va='center', ha='center', size='xx-large')\n",
    "    \n",
    "    plt.title('Matriz de confusão')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "        Mostra a Acurácia, F1 e a matrix de confusão para um modelo\n",
    "    \"\"\"\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n===== {name} =====\\n\")\n",
    "    print(\"   Acurácia (test) :\", \"{:.4f}\".format(accuracy_score(y_test, pred_test)))\n",
    "    print(\"   F1       (test) :\", \"{:.4f}\".format(f1_score(y_test, pred_test)))\n",
    "    \n",
    "    display_confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos dados\n",
    "dataset = pd.read_csv(\"dataset/PowerShellCorpus.ast.csv\")\n",
    "\n",
    "#Definindo X e y\n",
    "y = dataset.Label\n",
    "X = dataset.drop(['Path', 'Label'], axis=1)\n",
    "\n",
    "#Definindo treino e teste\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo Features com baixa variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = VarianceThreshold()\n",
    "_ = lv.fit(X_train)\n",
    "mask = lv.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de Features                           : {len(mask)}\")\n",
    "print(f\"Features com variância diferente de zero    : {sum(mask)}\")\n",
    "print(f\"Features com variância zero (removidas)     : {len(mask) - sum(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_zero_variance = X_train.loc[:, mask]\n",
    "X_test_non_zero_variance = X_test.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_zero_variance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = fit_model(LogisticRegression(random_state=0), X_train_non_zero_variance, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = fit_model(LogisticRegression(random_state=0), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Regressão Logística - 1\", model1, X_test_non_zero_variance, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Regressão Logística - 2\", model2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer    = 5\n",
    "neurons  = 20\n",
    "momentum = 0.9\n",
    "\n",
    "model3 = fit_model(MLPClassifier(hidden_layer_sizes=(layer, neurons), momentum=momentum, max_iter=5000), X_train_non_zero_variance, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"MLP\", model3, X_test_non_zero_variance, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
